{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession from pyspark.sql\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create my_spark or get it if already created\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading multiple csv in a directory\n",
    "df = spark.read.csv(['C:/Users/IP 320/Desktop/AUEB Assisgments/Dataset'],\\\n",
    "                    header=True, \\\n",
    "                    inferSchema = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of information in the dataset. For the assignment purpose, we will extract only the columns that might be useful to help us understand and answer from WHO, to WHO, and WHEN.\n",
    "\n",
    "Before we start on the aggregation, we need to understand our dataset.\n",
    "\n",
    "We will check the following and do the necessary transformation accordingly.\n",
    "\n",
    "- 1) Verify col and rows\n",
    "- 2) Datatype\n",
    "- 3) WhiteSpaces\n",
    "- 4) Remove any duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NAMELAST: string (nullable = true)\n",
      " |-- NAMEFIRST: string (nullable = true)\n",
      " |-- NAMEMID: string (nullable = true)\n",
      " |-- UIN: string (nullable = true)\n",
      " |-- BDGNBR: string (nullable = true)\n",
      " |-- ACCESS_TYPE: string (nullable = true)\n",
      " |-- TOA: string (nullable = true)\n",
      " |-- POA: string (nullable = true)\n",
      " |-- TOD: string (nullable = true)\n",
      " |-- POD: string (nullable = true)\n",
      " |-- APPT_MADE_DATE: string (nullable = true)\n",
      " |-- APPT_START_DATE: string (nullable = true)\n",
      " |-- APPT_END_DATE: string (nullable = true)\n",
      " |-- APPT_CANCEL_DATE: string (nullable = true)\n",
      " |-- Total_People: string (nullable = true)\n",
      " |-- LAST_UPDATEDBY: string (nullable = true)\n",
      " |-- POST: string (nullable = true)\n",
      " |-- LastEntryDate: string (nullable = true)\n",
      " |-- TERMINAL_SUFFIX: string (nullable = true)\n",
      " |-- visitee_namelast: string (nullable = true)\n",
      " |-- visitee_namefirst: string (nullable = true)\n",
      " |-- MEETING_LOC: string (nullable = true)\n",
      " |-- MEETING_ROOM: string (nullable = true)\n",
      " |-- CALLER_NAME_LAST: string (nullable = true)\n",
      " |-- CALLER_NAME_FIRST: string (nullable = true)\n",
      " |-- CALLER_ROOM: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Release Date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's print the schema to understand which variables are in the df and their types\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records are 3727296\n"
     ]
    }
   ],
   "source": [
    "total_records = df.count()\n",
    "print(\"The number of records are\", total_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few points to highlight.\n",
    "    - Visitor made an appointment and was given a unique appointment number(UIN)\n",
    "    - Appointment can be canceled\n",
    "    - Time of vistors arrival who actually turned up at whitehouse is recorded by the TOA column.\n",
    "\n",
    "Staff at the whitehouse cannot predict if the applicants will turn up or not, thus we can see that there are many missing values in the TOA colum.\n",
    "\n",
    "It may be useful for staff to plan the logistics requirement such as available rooms, security, and human traffic flow according to scheduled appointment start date. In this report, we will APPT_START DATE given that APPT_CANCEL_DAT is not null to analysis and answer the questions given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----+------------+---------------+----------------+------+\n",
      "|NAMEFIRST|           TOA|  POA|Total_People|APPT_START_DATE|APPT_CANCEL_DATE|   UIN|\n",
      "+---------+--------------+-----+------------+---------------+----------------+------+\n",
      "|   Donett| 2/26/12 18:50|B0402|           8|  2/26/12 19:00|            null|U83356|\n",
      "|    James| 2/26/12 18:50|B0402|           8|  2/26/12 19:00|            null|U83356|\n",
      "|Katherine|          null| null|           1|  5/18/12 11:00|            null|U04962|\n",
      "|Katherine| 5/24/12 14:49| K101|           1|  5/24/12 15:00|            null|U08899|\n",
      "|     Kirk|          null| null|          43|  9/18/12 11:30|            null|U39090|\n",
      "|    Dylan|          null| null|         268|  10/5/12 12:30|            null|U41863|\n",
      "|  Jeffrey|          null| null|         268|  10/5/12 12:30|            null|U41863|\n",
      "|    Robyn|          null| null|         268|  10/5/12 12:30|            null|U41863|\n",
      "| Kimberly|          null| null|         254| 12/15/12 20:30|            null|U59552|\n",
      "|     Anna|          null| null|         291|   9/19/12 8:30|            null|U38391|\n",
      "|     Anna|  9/19/12 9:42|D0101|         158|  9/19/12 10:00|            null|U39917|\n",
      "|    Blake|          null| null|         273|   4/5/12 10:30|            null|U91790|\n",
      "|   Carter|          null| null|         273|   4/5/12 10:30|            null|U91790|\n",
      "|  Gregory|          null| null|         273|   4/5/12 10:30|            null|U91790|\n",
      "|    Kelly|          null| null|         273|   4/5/12 10:30|            null|U91790|\n",
      "|   Ameena|          null| null|         277|   4/3/12 10:30|            null|U92835|\n",
      "|   Azadeh|          null| null|         223|   8/18/12 9:30|            null|U29960|\n",
      "|   Azadeh|          null| null|           4|  8/18/12 16:45|            null|U25359|\n",
      "|     Mary|          null| null|         300|  2/17/12 11:00|            null|U80410|\n",
      "|   Jameel|  3/30/12 9:09|D1S01|          92|   3/30/12 9:00|            null|U93143|\n",
      "|   Jameel|          null| null|         232|   4/5/12 13:30|            null|U95097|\n",
      "|   Jameel|          null| null|           1| 11/19/12 16:00|            null|U54134|\n",
      "|     Anne|          null| null|         275| 10/18/12 11:00|            null|U45319|\n",
      "|   Joseph|10/20/12 15:26|B0402|           6| 10/20/12 15:00|            null|U48020|\n",
      "|  Daniyal|          null| null|         275|   5/8/12 10:30|            null|U03388|\n",
      "|   Kellie|          null| null|         188|   5/17/12 9:30|            null|U06630|\n",
      "|    Carly|          null| null|         297|  3/17/12 13:30|            null|U86359|\n",
      "|   Sandra|          null| null|         297|  3/17/12 13:30|            null|U86359|\n",
      "|    Wayne|          null| null|         297|  3/17/12 13:30|            null|U86359|\n",
      "|ELIZABETH|          null| null|         520| 11/28/12 16:30|            null|U55274|\n",
      "+---------+--------------+-----+------------+---------------+----------------+------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('NAMEFIRST','TOA','POA','Total_People','APPT_START_DATE','APPT_CANCEL_DATE','UIN').filter(df.Total_People.isNotNull()).show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the relevant ifnormation that we require for the analysis\n",
    "cols_select =['NAMELAST',\n",
    "             'NAMEFIRST',\n",
    "             'APPT_START_DATE',\n",
    "             'APPT_CANCEL_DATE',\n",
    "             'Total_People',\n",
    "             'visitee_namelast',\n",
    "             'visitee_namefirst',\n",
    "             'UIN']\n",
    "data = df.select(cols_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------------+----------------+------------+----------------+-----------------+------+\n",
      "|NAMELAST|NAMEFIRST|APPT_START_DATE|APPT_CANCEL_DATE|Total_People|visitee_namelast|visitee_namefirst|   UIN|\n",
      "+--------+---------+---------------+----------------+------------+----------------+-----------------+------+\n",
      "|    Aaby|   Donett|  2/26/12 19:00|            null|           8|            Aaby|             Kate|U83356|\n",
      "|    Aaby|    James|  2/26/12 19:00|            null|           8|            Aaby|             Kate|U83356|\n",
      "|    Aaby|Katherine|  5/18/12 11:00|            null|           1|            Ross|             Adam|U04962|\n",
      "|    Aaby|Katherine|  5/24/12 15:00|            null|           1|            Ross|             Adam|U08899|\n",
      "| Aadalen|     Kirk|  9/18/12 11:30|            null|          43|            null|            POTUS|U39090|\n",
      "|  AAFEDT|  ANTHONY|    6/8/12 8:00|            null|        null|            null|             null|U13475|\n",
      "|  AAFEDT|     CODY|    6/8/12 8:00|            null|        null|            null|             null|U13475|\n",
      "|  AAFEDT|  RAYMOND|    6/8/12 8:00|            null|        null|            null|             null|U13475|\n",
      "|  Aafedt|    Dylan|  10/5/12 12:30|            null|         268|          OFFICE|         VISITORS|U41863|\n",
      "|  Aafedt|  Jeffrey|  10/5/12 12:30|            null|         268|          OFFICE|         VISITORS|U41863|\n",
      "|  Aafedt|    Robyn|  10/5/12 12:30|            null|         268|          OFFICE|         VISITORS|U41863|\n",
      "| Aagaard| Kimberly| 12/15/12 20:30|            null|         254|          OFFICE|         VISITORS|U59552|\n",
      "| AAGENES|     ANNA|        9/19/12|            null|        null|            null|             null|  null|\n",
      "| Aagenes|     Anna|   9/19/12 8:30|            null|         291|          OFFICE|         VISITORS|U38391|\n",
      "| Aagenes|     Anna|  9/19/12 10:00|            null|         158|        RAGHAVAN|           GAUTAM|U39917|\n",
      "|  Aakhus|    Blake|   4/5/12 10:30|            null|         273|          OFFICE|         VISITORS|U91790|\n",
      "|  Aakhus|   Carter|   4/5/12 10:30|            null|         273|          OFFICE|         VISITORS|U91790|\n",
      "|  Aakhus|  Gregory|   4/5/12 10:30|            null|         273|          OFFICE|         VISITORS|U91790|\n",
      "|  Aakhus|    Kelly|   4/5/12 10:30|            null|         273|          OFFICE|         VISITORS|U91790|\n",
      "|  AalAli|   Ameena|   4/3/12 10:30|            null|         277|          OFFICE|         VISITORS|U92835|\n",
      "+--------+---------+---------------+----------------+------------+----------------+-----------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling date timestamp, Filling NAs and Casting Datatypes\n",
    "\n",
    "We will handle them one by one.\n",
    "\n",
    "First we start off by converting string type data which should be timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NAMELAST', 'string'),\n",
       " ('NAMEFIRST', 'string'),\n",
       " ('APPT_START_DATE', 'string'),\n",
       " ('APPT_CANCEL_DATE', 'string'),\n",
       " ('Total_People', 'string'),\n",
       " ('visitee_namelast', 'string'),\n",
       " ('visitee_namefirst', 'string'),\n",
       " ('UIN', 'string')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gives us the idea of datatype and perform necessary transformation.\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dayofmonth,from_unixtime,month, unix_timestamp, year,date_format, to_timestamp, col\n",
    "\n",
    "#the datatype of the column 'APPT_START_DATE' is string\n",
    "#I do the conversion and created column datetime2 which is time stamp\n",
    "\n",
    "data = data.withColumn('datetime2', to_timestamp(col('APPT_START_DATE'), \"MM/dd/yy\").cast('timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract month, year, day information\n",
    "#create new column for each row of day, month, year\n",
    "\n",
    "data = data.withColumn(\"Appt_month\", month(data.datetime2)).\\\n",
    "            withColumn(\"Appt_year\", year(data.datetime2)).\\\n",
    "            withColumn(\"Appt_day\", dayofmonth(data.datetime2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract day of week\n",
    "#create new columns of Day of week\n",
    "\n",
    "data = data.withColumn(\"DayOfWeek\", date_format(\"datetime2\",\"EEEE\")).\\\n",
    "      withColumn(\"DayOfWeek_number\", date_format(\"datetime2\",\"u\")) # and numerics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we tackle the string values that should be numeric values by casting them to Integer type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "data = data.withColumn(\"Total_People\", data[\"Total_People\"].cast(IntegerType())).\\\n",
    "            withColumn(\"DayofWeek_number\", data[\"DayofWeek_number\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import trim\n",
    "\n",
    "data = data.withColumn('visitee_namelast', trim(data.visitee_namelast))\n",
    "data = data.withColumn('visitee_namefirst', trim(data.visitee_namefirst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, we want to analysis those appointments that is not cancelled, so we filter out the Null values in APPT_CANCEL_DATE. \n",
    "\n",
    "We also drop the columns that are no longer useful as we have created new ones with the correct data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by taking the rows that are null\n",
    "data2 = data.filter(data.APPT_CANCEL_DATE.isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data2.drop('APPT_START_DATE','APPT_CANCEL_DATE','datetime2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----------------+-----------------+-----+----+---+---------+-------------+-----------------+\n",
      "|NAMELAST|NAMEFIRST|visitee_namelast|visitee_namefirst|month|year|day|DayOfWeek|Total_People2|DayofWeek_number2|\n",
      "+--------+---------+----------------+-----------------+-----+----+---+---------+-------------+-----------------+\n",
      "|       0|        0|               0|                0|    0|   0|  0|        0|            0|                0|\n",
      "+--------+---------+----------------+-----------------+-----+----+---+---------+-------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data_agg = data.agg(*[F.count(F.when(F.isnull(c), c)).alias(c) for c in data.columns])\n",
    "#data_agg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all the steps above, we are finally ready to move on to our questions!\n",
    "\n",
    "The first question is asking us to find the top 20 visitor. We did a groupby First and Last name and order the count of each names in descending order. This information disregard the period they visited the Whitehouse but we can be sure they are frequent vistors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1 Who are the top 20 visitors?\n",
    "by_visitor = data.select(data.NAMELAST, data.NAMEFIRST).groupBy(\"NAMELAST\",\"NAMEFIRST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-----+\n",
      "|    NAMELAST|NAMEFIRST|count|\n",
      "+------------+---------+-----+\n",
      "|        Hash|  Michael|  726|\n",
      "|    Tavenner|  Marilyn|  519|\n",
      "|        Hoff|    James|  482|\n",
      "|BrooksLaSure| Chiquita|  410|\n",
      "|     Levitis|    Jason|  384|\n",
      "|       Borzi|  Phyllis|  368|\n",
      "|    Fontenot|   Yvette|  350|\n",
      "|      Khalid|   Aryana|  341|\n",
      "|        Mann|  Cynthia|  323|\n",
      "|      Werner|   Sharon|  310|\n",
      "|        Choe|  Kenneth|  305|\n",
      "|       Smith|  Michael|  304|\n",
      "|       Jones|   Daniel|  303|\n",
      "|      Turner|      Amy|  302|\n",
      "|    Morrison|    Helen|  295|\n",
      "|  Livingston|Catherine|  295|\n",
      "|     Kronick|  Richard|  292|\n",
      "|       Lewis|     Caya|  292|\n",
      "|     Maguire|   Daniel|  290|\n",
      "|     Schultz|  William|  283|\n",
      "+------------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#.count() in pyspark is a lazy operation which literally counts every row so it took a long time.\n",
    "by_visitor.count().orderBy(\"count\", ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the period when Obama is the president, he is affectionally referred to as \"POTUS\" which stands for President of the United States and first lady Michelle Obama as \"FLOTUS\" which stands for First Lady of the United States.\n",
    "\n",
    "From our results, we can see that the majority of the vistors visted the vistors office. During these period, Obama welcomed visitors to the whitehouse and frequently organizes group tours, parties for Halloween and Christmas and many other ocassions. We are not surprise to see as well they are also among the top visitee. \n",
    "\n",
    "Kyle Lierman serves as a Senior Associate Director of Public Engagement and Senior Policy Advisor in the White House Office of Public Engagement. Perhaps he is busy with the media, and reporters I would assume. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import upper\n",
    "\n",
    "data = data.withColumn('visitee_namefirst', upper(col('visitee_namefirst')))\n",
    "data = data.withColumn('visitee_namelast', upper(col('visitee_namelast')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+-------+\n",
      "|visitee_namefirst|visitee_namelast|  count|\n",
      "+-----------------+----------------+-------+\n",
      "|         VISITORS|          OFFICE|2271048|\n",
      "|            POTUS|            null|  98674|\n",
      "|     POTUS/FLOTUS|            null|  24155|\n",
      "|             KYLE|         LIERMAN|  15590|\n",
      "|           JEANNE|         LAMBREW|  14667|\n",
      "|            POTUS|               /|  10876|\n",
      "|           OFFICE|          HETZEL|  10672|\n",
      "|             PAUL|        MONTEIRO|   9549|\n",
      "|           FLOTUS|            null|   9319|\n",
      "|              MAX|         DOEBLER|   9238|\n",
      "|           GAUTAM|        RAGHAVAN|   7468|\n",
      "|             GREG|          NELSON|   7203|\n",
      "|         VICTORIA|      MCCULLOUGH|   7127|\n",
      "|          HEATHER|          FOSTER|   7062|\n",
      "|           LAUREN|           KELLY|   6427|\n",
      "|            NANCY|           HOGAN|   6422|\n",
      "|            KAREN|      RICHARDSON|   5666|\n",
      "|              JON|          CARSON|   4834|\n",
      "|            JULIE|       RODRIGUEZ|   4736|\n",
      "|          CHELSEA|       BOLLINGER|   4689|\n",
      "+-----------------+----------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1.2 Who are the top 20 visitees?\n",
    "#Filter and GroupBy visitee\n",
    "\n",
    "by_visitee2 = data.select('visitee_namefirst','visitee_namelast').\\\n",
    "            filter(data.visitee_namefirst.isNotNull()).\\\n",
    "            groupBy('visitee_namefirst','visitee_namelast').\\\n",
    "            count().\\\n",
    "            orderBy(\"count\", ascending=False).\\\n",
    "            show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this third question, we would like to understand who gets the most appointments from who. \n",
    "We follow the steps to select the names of visitee and visitors and do a groupby and count the number of times they have scheduled an appointment. Since we are not particular on the dates, we will omit this information. \n",
    "\n",
    "Again, we order the count in descending order to see the top pairs. In the result, we see that Jeanne Lambrew is very busy with many people and Joanne Hoff gets most of her appointments from James Hoff.\n",
    "\n",
    "I decide to dig a bit further and found some information why James Hoff is visiting Joanne Hoff. We may look at it at the link below.\n",
    "\n",
    "https://www.reddit.com/r/RBI/comments/44thud/who_is_james_c_hoff_he_has_had_the_third_most/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3 Who are the top 20 visitor-visitee pairs?\n",
    "by_pairs = data.select(\"NAMELAST\", \"NAMEFIRST\", \"visitee_namelast\", \"visitee_namefirst\").groupBy(\"NAMELAST\",\"NAMEFIRST\",\"visitee_namelast\",\"visitee_namefirst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+----------------+-----------------+-----+\n",
      "|    NAMELAST|NAMEFIRST|visitee_namelast|visitee_namefirst|count|\n",
      "+------------+---------+----------------+-----------------+-----+\n",
      "|        Hash|  Michael|         LAMBREW|           JEANNE|  532|\n",
      "|        Hoff|    James|            HOFF|           JOANNE|  387|\n",
      "|    Tavenner|  Marilyn|         LAMBREW|           JEANNE|  382|\n",
      "|BrooksLaSure| Chiquita|         LAMBREW|           JEANNE|  334|\n",
      "|    Fontenot|   Yvette|         LAMBREW|           JEANNE|  293|\n",
      "|     Levitis|    Jason|         LAMBREW|           JEANNE|  291|\n",
      "|      Khalid|   Aryana|         LAMBREW|           JEANNE|  289|\n",
      "|        Mann|  Cynthia|         LAMBREW|           JEANNE|  276|\n",
      "|     Kronick|  Richard|         LAMBREW|           JEANNE|  253|\n",
      "|        Choe|  Kenneth|         LAMBREW|           JEANNE|  249|\n",
      "|  Livingston|Catherine|         LAMBREW|           JEANNE|  241|\n",
      "|       Borzi|  Phyllis|         LAMBREW|           JEANNE|  241|\n",
      "|     Maguire|   Daniel|         LAMBREW|           JEANNE|  237|\n",
      "|    Morrison|    Helen|         LAMBREW|           JEANNE|  236|\n",
      "|      Turner|      Amy|         LAMBREW|           JEANNE|  236|\n",
      "|      Larsen|   Steven|         LAMBREW|           JEANNE|  212|\n",
      "|      Obrien|     John|         LAMBREW|           JEANNE|  205|\n",
      "|       Davis| Jonathan|         LAMBREW|           JEANNE|  201|\n",
      "|       Foley| Jonathan|         LAMBREW|           JEANNE|  198|\n",
      "|       Cohen|     Gary|         LAMBREW|           JEANNE|  196|\n",
      "+------------+---------+----------------+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "by_pairs.count().orderBy(\"count\", ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are answering the question for WHEN and we are using the dates. We will try two different ways trying to see each results.\n",
    "\n",
    "In the first one, we count the number of appointments considering that it will be important for the staff to how many groups. \n",
    "\n",
    "In the second one, we sum up the number of people visiting that day. Of course again we dont know if they will cancel the appointment. This will help to see how crowded the Whitehouse will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+-----+\n",
      "|Appt_day|Appt_month|Appt_year|count|\n",
      "+--------+----------+---------+-----+\n",
      "|      14|         3|     2012| 9135|\n",
      "|       9|        12|     2009| 8966|\n",
      "|      18|        12|     2010| 8876|\n",
      "|      19|         5|     2010| 8740|\n",
      "|      11|        12|     2009| 8689|\n",
      "|      18|         8|     2011| 8606|\n",
      "|      11|        12|     2010| 8387|\n",
      "|      21|        12|     2010| 8227|\n",
      "|      22|        12|     2010| 8215|\n",
      "|       7|        12|     2013| 8092|\n",
      "|      18|        12|     2009| 8079|\n",
      "|      19|        12|     2012| 7833|\n",
      "|      18|         6|     2010| 7815|\n",
      "|       4|        12|     2009| 7783|\n",
      "|       8|        12|     2012| 7477|\n",
      "|      14|        12|     2013| 7464|\n",
      "|      15|        12|     2012| 7426|\n",
      "|      20|        12|     2010| 7420|\n",
      "|      21|        12|     2012| 7412|\n",
      "|      23|        12|     2009| 7355|\n",
      "+--------+----------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1.4 What were the top 20 most busy days?\n",
    "\n",
    "busiest_day = data.select(\"Appt_day\",\"Appt_month\",\"Appt_year\",\"Total_People\").\\\n",
    "            filter(data.Appt_day.isNotNull()).\\\n",
    "            filter(data.Appt_month.isNotNull()).\\\n",
    "            groupBy(\"Appt_day\",\"Appt_month\",\"Appt_year\").\\\n",
    "            count().\\\n",
    "            orderBy('count', ascending= False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "busiest_day2 = data.select(\"Appt_day\",\"Appt_month\",\"Appt_year\",\"Total_People\").\\\n",
    "            filter(data.Appt_day.isNotNull()).\\\n",
    "            filter(data.Appt_month.isNotNull()).\\\n",
    "            groupBy(\"Appt_day\",\"Appt_month\",\"Appt_year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+-----------------+\n",
      "|Appt_day|Appt_month|Appt_year|sum(Total_People)|\n",
      "+--------+----------+---------+-----------------+\n",
      "|      14|         3|     2012|         33946485|\n",
      "|      19|         5|     2010|         21507390|\n",
      "|       8|         9|     2011|         17779960|\n",
      "|      29|         6|     2010|         17389336|\n",
      "|       9|        12|     2009|         16717218|\n",
      "|       7|         6|     2011|         16631811|\n",
      "|      13|        10|     2011|         16509741|\n",
      "|       7|         4|     2013|         16251305|\n",
      "|       4|         7|     2012|         14286691|\n",
      "|      22|         1|     2013|         14031755|\n",
      "|       7|        12|     2009|         13735919|\n",
      "|       4|         7|     2010|         13090176|\n",
      "|      11|        12|     2009|         12688467|\n",
      "|       4|         7|     2011|          9490141|\n",
      "|      10|        12|     2009|          8158890|\n",
      "|       4|        12|     2009|          7352342|\n",
      "|      31|        10|     2010|          7202542|\n",
      "|      31|        10|     2009|          7049490|\n",
      "|      14|        12|     2009|          6883421|\n",
      "|      24|        11|     2009|          4974478|\n",
      "+--------+----------+---------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "busiest_day2.agg(F.sum(data.Total_People)).orderBy(\"sum(Total_People)\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 2009 December is the most busiest month in the year. It is the first inauguration of Barack Obama as the 44th President of the United States took place on Tuesday, January 20, 2009. And in December, the first family organizes their first Christmas events, and many other events that year. \n",
    "\n",
    "In 2012, there's an election and Obama participated in it and won. It did not happen in March 2012 but that month is also second busiest month.\n",
    "\n",
    "https://obamawhitehouse.archives.gov/realitycheck/briefing-room/Statements-and-Releases/2009/09?page=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----------------+\n",
      "|Appt_month|Appt_year|sum(Total_People)|\n",
      "+----------+---------+-----------------+\n",
      "|        12|     2009|         85846825|\n",
      "|         3|     2012|         51540240|\n",
      "|         6|     2010|         44182242|\n",
      "|         6|     2011|         40340230|\n",
      "|      null|     null|         40272335|\n",
      "|         5|     2010|         40084890|\n",
      "|        10|     2011|         35322342|\n",
      "|        12|     2010|         34723022|\n",
      "|         7|     2010|         34715110|\n",
      "|         7|     2011|         31705584|\n",
      "|         9|     2011|         31678363|\n",
      "|         7|     2012|         30639110|\n",
      "|        12|     2012|         28373883|\n",
      "|        12|     2011|         26899485|\n",
      "|         3|     2010|         26632273|\n",
      "|        10|     2010|         25563169|\n",
      "|        12|     2013|         22655331|\n",
      "|        10|     2009|         21165038|\n",
      "|         5|     2011|         20966141|\n",
      "|         3|     2011|         20745076|\n",
      "+----------+---------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1.5 What were the top 20 most busy months-years?\n",
    "busiest_month = data.select(\"Appt_month\",\"Appt_year\",\"Total_People\").groupBy(\"Appt_month\",\"Appt_year\")\n",
    "busiest_month.agg(F.sum(data.Total_People)).orderBy(\"sum(Total_People)\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday. Which day is the favourite day to visit the whitehouse?\n",
    "\n",
    "Firstly, we checked the spelling if the system is correct. They are okie. \n",
    "\n",
    "Next we took the total of the number of people visited based on the DayofWeek column. Not surprising they are not a fan of Monday events. Of course no one like weekend work and appointments so it's normal that weekends does not have so much counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+------+\n",
      "|DayOfWeek|DayOfWeek_number| count|\n",
      "+---------+----------------+------+\n",
      "| Saturday|               6|685829|\n",
      "|   Sunday|               7|112339|\n",
      "|   Friday|               5|726778|\n",
      "|   Monday|               1|232728|\n",
      "|Wednesday|               3|616971|\n",
      "|  Tuesday|               2|637941|\n",
      "| Thursday|               4|623846|\n",
      "+---------+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1.6 What was the order of popularity of days of week for visits?\n",
    "weekDaysCount  = data.filter(data.DayOfWeek.isNotNull()).\\\n",
    "                groupBy([\"DayOfWeek\", \"DayOfWeek_number\"]).\\\n",
    "                count()\n",
    "\n",
    "weekDaysCount.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+-----------------+\n",
      "|DayOfWeek|DayOfWeek_number|sum(Total_People)|\n",
      "+---------+----------------+-----------------+\n",
      "|Wednesday|               3|        205640558|\n",
      "|  Tuesday|               2|        180589415|\n",
      "| Saturday|               6|        179292977|\n",
      "|   Friday|               5|        178059876|\n",
      "| Thursday|               4|        161285552|\n",
      "|   Monday|               1|         61812155|\n",
      "|   Sunday|               7|         41035499|\n",
      "+---------+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "popular_DayofWeek = data.select(\"DayOfWeek\",\"DayOfWeek_number\",\"Total_People\").filter(data.DayOfWeek.isNotNull()).groupBy(\"DayOfWeek\",\"DayOfWeek_number\")\n",
    "popular_DayofWeek.agg(F.sum(data.Total_People)).orderBy(\"sum(Total_People)\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are at our last question on Whitehouse before moving on the machine learning portion. We want to understand which month is the most popular month to visit. Regardless of year because this time, we want to understand if there are any seasons or period which has the highest visitors.\n",
    "\n",
    "December is top on the list for highest appointments made and most number of visitors to the whitehouse. December is the christmas seasons and so is the whitehouse and first lady welcoming their guest and visitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|Appt_month| count|\n",
      "+----------+------+\n",
      "|        12|556349|\n",
      "|         1|218811|\n",
      "|         6|320055|\n",
      "|         3|403654|\n",
      "|         5|280021|\n",
      "|         9|239251|\n",
      "|         4|277436|\n",
      "|         8|261852|\n",
      "|         7|266468|\n",
      "|        10|329885|\n",
      "|        11|269890|\n",
      "|         2|212760|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1.7 What was the order of popularity of months for visits?\n",
    "monthCount  = data.filter(data.Appt_month.isNotNull()).groupBy([\"Appt_month\"]).count()\n",
    "monthCount.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|Appt_month|sum(Total_People)|\n",
      "+----------+-----------------+\n",
      "|        12|        198498546|\n",
      "|         3|        121285047|\n",
      "|        10|         99627265|\n",
      "|         7|         97128915|\n",
      "|         6|         86522222|\n",
      "|         5|         77416391|\n",
      "|         4|         73297811|\n",
      "|         8|         59129261|\n",
      "|         9|         58996443|\n",
      "|        11|         53462012|\n",
      "|         1|         46034491|\n",
      "|         2|         36317628|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "popular_MonthofYear = data.select(\"Appt_month\",\"Total_People\").filter(data.Appt_month.isNotNull()).groupBy(\"Appt_month\")\n",
    "popular_MonthofYear.agg(F.sum(data.Total_People)).orderBy(\"sum(Total_People)\", ascending = False).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
